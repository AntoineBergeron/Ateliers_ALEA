for(j in 1:3){
reponse <- 0
for (i in 1:6) {
reponse <- reponse + ButsResult[i,j]*(i-1)
}
ButsMoyen2[j] <- reponse/sum(ButsResult[,j])
}
ButsMoyen2
?colnames
ButsResult <- read.table(file = "donnees/ButsResult.txt", sep="\t", header = TRUE)
ButsResult
View(ButsResult)
ButsMoyen <- c()
ButsMoyen[1] <- (ButsResult[1,1]*0 + ButsResult[2,1]*1 + ButsResult[3,1]*2 + ButsResult[4,1]*3 + ButsResult[5,1]*4 + ButsResult[6,1]*5)/sum(ButsResult[,1])
ButsMoyen[2] <- (ButsResult[1,2]*0 + ButsResult[2,2]*1 + ButsResult[3,2]*2 + ButsResult[4,2]*3 + ButsResult[5,2]*4 + ButsResult[6,2]*5)/sum(ButsResult[,2])
ButsMoyen[3] <- (ButsResult[1,3]*0 + ButsResult[2,3]*1 + ButsResult[3,3]*2 + ButsResult[4,3]*3 + ButsResult[5,3]*4 + ButsResult[6,3]*5)/sum(ButsResult[,3])
ButsMoyen
ButsMoyen2 <- c()
for(j in 1:3){
reponse <- 0
for (i in 1:6) {
reponse <- reponse + ButsResult[i,j]*(i-1)
}
ButsMoyen2[j] <- reponse/sum(ButsResult[,j])
}
ButsMoyen2
ButsResult
View(ButsResult)
VecBut <- c(0:5,0:5,0:5)
VecBut
tableau <- VecBut * ButsResult
tableau
colSums(tableau)
colSums(ButsResult)
ButsMoyen3 <- colSums(tableau)/colSums(ButsResult)
ButsMoyen3
as.data.frame(ButsMoyen)
t(as.data.frame(ButsMoyen))
df <- t(as.data.frame(ButsMoyen))
df
?colnames
colnames(df) <- c("Défaite","Égalité","Victoire")
df
donnees <- read.table(file = 'C:/Users/bera1923/Desktop/CeCS - Consultations/Clients et Clientes/Zidane Toffa/donnees.txt', sep = "\t", header = TRUE)
Att <- donnees[,1]                   # Copie la première colonne
donnees <- donnees[,-1]              # Enlève la première colonne
donneesFinal <- cbind(donnees,Att)   # Colle la copie à la fin du tableau
colnames(donneesFinal) <- c("RecBro", "Rxt", "Slot", "Snir", "Tim", "TotBusy", "TotLost", "Att")
set.seed(12)
echaEntr <- donneesFinal$Att %>%
createDataPartition(p = 0.8, list = FALSE)    # 80% pour entraînement, 20% pour Test
donneesEntr  <- donneesFinal[echaEntr, ]  # données d'entraînement
library(tidyverse) # Stepwise Logistic Regression
library(caret) # Stepwise Logistic Regression
library(MASS) # Stepwise Logistic Regression
library(glmnet) # Arriver a bien capter les bons prédicteurs
library(copula) # Estimation à l'aide de copules
library(VineCopula) # Estimation à l'aide de copules
donnees <- read.table(file = 'C:/Users/bera1923/Desktop/CeCS - Consultations/Clients et Clientes/Zidane Toffa/donnees.txt', sep = "\t", header = TRUE)
Att <- donnees[,1]                   # Copie la première colonne
donnees <- donnees[,-1]              # Enlève la première colonne
donneesFinal <- cbind(donnees,Att)   # Colle la copie à la fin du tableau
colnames(donneesFinal) <- c("RecBro", "Rxt", "Slot", "Snir", "Tim", "TotBusy", "TotLost", "Att")
set.seed(12)
echaEntr <- donneesFinal$Att %>%
createDataPartition(p = 0.8, list = FALSE)    # 80% pour entraînement, 20% pour Test
donneesEntr  <- donneesFinal[echaEntr, ]  # données d'entraînement
donneesTest <- donneesFinal[-echaEntr, ]  # données test
# Pour le modèle lasso
x <- model.matrix(Att~., donneesEntr)[,-1]   # Sur R, on doit séparer les variables x et y pour Lasso
y <- donneesEntr$Att                         # On obtient x et y ainsi
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
# Fit le modèle final sur les données d'entraînement
model.lasso <- glmnet(x, y, alpha = 1, family = "binomial",
lambda = cv.lasso$lambda.min)
# Coefficients de la régression
coef(model.lasso)
# Prédictions
x.test <- model.matrix(Att ~., donneesTest)[,-1]
prob <- model.lasso %>% predict(newx = x.test)
ClassPred <- ifelse(prob > 0.5, 1, 0)
# Précision
ClassObs <- donneesTest$Att
mean(ClassPred == ClassObs)
# Stepwise model
step.model <- glm(Att ~., data = donneesEntr, family = binomial, control = glm.control(maxit = 50)) %>%
stepAIC(trace = TRUE)
# Coefficients de la régression
coef(step.model)
summary(step.model)
# Prédictions
prob <- predict(step.model, donneesTest, type = "response")
ClassPred <- ifelse(prob > 0.5, 1, 0)
# Précision
ClassObs <- donneesTest$Att
mean(ClassPred==donneesEntr$Att)
cor(donneesFinal, method = "pearson")
col1 <- donneesFinal[,1]  # RecBro
col2 <- donneesFinal[,2]  # Rxt
col3 <- donneesFinal[,6]  # TotBusy
col4 <- donneesFinal[,8]  # Att
ntabFinal <- cbind.data.frame(col1,col2,col3,col4)           # coller les 4 colonnes
colnames(ntabFinal) <- c("RecBro", "Rxt", "TotBusy", "Att")  # renommer les colonnes
ntabFinal
es_p <- mean(ntabFinal[,4])   # Effectue la moyenne des Att (Somme des 0 et 1 divisé en n = 240 attaques)
es_p   # la probabilité d'attaque est de 0.2083333
Fn_1 <- ecdf(ntabFinal[,1])  # Fonction de répartition empirique
Fn_2 <- ecdf(ntabFinal[,2])  # Fonction de répartition empirique
Fn_3 <- ecdf(ntabFinal[,3])  # Fonction de répartition empirique
Fn_4 <- ecdf(ntabFinal[,4])  # Fonction de répartition empirique
plot(Fn_1, verticals = TRUE, do.points = FALSE, main = "Fonction de répartition de la variable RecBro")
plot(Fn_2, verticals = TRUE, do.points = FALSE, main = "Fonction de répartition de la variable Rxt")
plot(Fn_3, verticals = TRUE, do.points = FALSE, main = "Fonction de répartition de la variable TotBusy")
plot(Fn_4, verticals = TRUE, do.points = FALSE, main = "Fonction de répartition de la variable Att")
matF <- matrix(NA, nrow = nrow(ntabFinal), ncol = ncol(ntabFinal))     # Création de la matrice des répartition
matF[,1] <- nrow(ntabFinal) / (nrow(ntabFinal)+1) * Fn_1(ntabFinal[,1])  # première colonne (Rescaled distribution)
matF[,2] <- nrow(ntabFinal) / (nrow(ntabFinal)+1) * Fn_2(ntabFinal[,2])  # deuxième colonne (Rescaled distribution)
matF[,3] <- nrow(ntabFinal) / (nrow(ntabFinal)+1) * Fn_3(ntabFinal[,3])  # troisième colonne (Rescaled distribution)
matF[,4] <- nrow(ntabFinal) / (nrow(ntabFinal)+1) * Fn_4(ntabFinal[,4])  # troisième colonne (Rescaled distribution)
matF
MatntabFinal <- as.matrix(ntabFinal)
# Copules: 1 = Gaussienne, 2 = Student, 3 = Gumbel, 4 = Clayton, 5 = Frank, 6 = Joe,
coefficient <- function(copule, matrice){
if(copule == 1){
cop <- normalCopula(dim = 4)
t <- "La copule gaussienne possède un paramètre égal à"
} else if(copule == 2){
cop <- tCopula(dim = 4)
t <- "La copule Student possède un paramètre égal à"
} else if(copule == 3){
cop <- gumbelCopula(dim = 4)
t <- "La copule Gumbel possède un paramètre égal à"
} else if(copule == 4){
cop <- claytonCopula(dim = 4)
t <- "La copule Clayton possède un paramètre égal à"
} else if(copule == 5){
cop <- frankCopula(dim = 4)
t <- "La copule de Frank possède un paramètre égal à"
} else if(copule == 6){
cop <- joeCopula(dim = 4)
t <- "La copule de Joe possède un paramètre égal à"
}
fit <- fitCopula(cop, matrice, method = "mpl")
return(paste(t, coef(fit), sep = " "))
}
coefficient(1,matF)
coefficient(2,matF) # possède le paramètre ainsi que le degré de liberté!
coefficient(3,matF)
coefficient(4,matF)
coefficient(5,matF)
coefficient(6,matF)
# Copules: 1 = Gaussienne, 2 = Student, 3 = Gumbel, 4 = Clayton, 5 = Frank, 6 = Joe,
coefficient <- function(copule, matrice){
if(copule == 1){
cop <- normalCopula(dim = 4)
t <- "La copule gaussienne possède un paramètre égal à"
} else if(copule == 2){
cop <- tCopula(dim = 4)
t <- "La copule Student possède un paramètre égal à"
} else if(copule == 3){
cop <- gumbelCopula(dim = 4)
t <- "La copule Gumbel possède un paramètre égal à"
} else if(copule == 4){
cop <- claytonCopula(dim = 4)
t <- "La copule Clayton possède un paramètre égal à"
} else if(copule == 5){
cop <- frankCopula(dim = 4)
t <- "La copule de Frank possède un paramètre égal à"
} else if(copule == 6){
cop <- joeCopula(dim = 4)
t <- "La copule de Joe possède un paramètre égal à"
}
fit <- fitCopula(cop, matrice, method = "mpl")
return(paste(t, coef(fit), sep = " "))
return(coef(fit))
}
coefficient(1,matF)
# Copules: 1 = Gaussienne, 2 = Student, 3 = Gumbel, 4 = Clayton, 5 = Frank, 6 = Joe,
coefficient <- function(copule, matrice){
if(copule == 1){
cop <- normalCopula(dim = 4)
t <- "La copule gaussienne possède un paramètre égal à"
} else if(copule == 2){
cop <- tCopula(dim = 4)
t <- "La copule Student possède un paramètre égal à"
} else if(copule == 3){
cop <- gumbelCopula(dim = 4)
t <- "La copule Gumbel possède un paramètre égal à"
} else if(copule == 4){
cop <- claytonCopula(dim = 4)
t <- "La copule Clayton possède un paramètre égal à"
} else if(copule == 5){
cop <- frankCopula(dim = 4)
t <- "La copule de Frank possède un paramètre égal à"
} else if(copule == 6){
cop <- joeCopula(dim = 4)
t <- "La copule de Joe possède un paramètre égal à"
}
fit <- fitCopula(cop, matrice, method = "mpl")
return(list(paste(t, coef(fit), sep = " ")),coef(fit))
}
coefficient(1,matF)
# Copules: 1 = Gaussienne, 2 = Student, 3 = Gumbel, 4 = Clayton, 5 = Frank, 6 = Joe,
coefficient <- function(copule, matrice){
if(copule == 1){
cop <- normalCopula(dim = 4)
t <- "La copule gaussienne possède un paramètre égal à"
} else if(copule == 2){
cop <- tCopula(dim = 4)
t <- "La copule Student possède un paramètre égal à"
} else if(copule == 3){
cop <- gumbelCopula(dim = 4)
t <- "La copule Gumbel possède un paramètre égal à"
} else if(copule == 4){
cop <- claytonCopula(dim = 4)
t <- "La copule Clayton possède un paramètre égal à"
} else if(copule == 5){
cop <- frankCopula(dim = 4)
t <- "La copule de Frank possède un paramètre égal à"
} else if(copule == 6){
cop <- joeCopula(dim = 4)
t <- "La copule de Joe possède un paramètre égal à"
}
fit <- fitCopula(cop, matrice, method = "mpl")
return(list((paste(t, coef(fit), sep = " ")),coef(fit)))
}
coefficient(1,matF)
param_gauss <- coefficient(1,matF)[2]
param_gauss <- coefficient(1,matF)[2][1]
View(param_gauss)
param_gauss
param_gauss <- coefficient(1,matF)[2][[1]]
param_gauss
param_gauss * 2
coefficient(2,matF) # possède le paramètre ainsi que le degré de liberté!
param_stud <- coefficient(1,matF)[2][[1]]
param_stud <- coefficient(2,matF)[2][[1]]
param_stud
coefficient(1,matF)
param_gauss <- coefficient(1,matF)[2][[1]]  # paramètre de la copule gaussienne
coefficient(2,matF) # possède le paramètre ainsi que le degré de liberté!
param_stud <- coefficient(2,matF)[2][[1]]   # paramètres de la copule de Student
coefficient(3,matF)
param_gumb <- coefficient(3,matF)[2][[1]]  # paramètre de la copule gaussienne
coefficient(4,matF)
param_clay <- coefficient(4,matF)[2][[1]]  # paramètre de la copule gaussienne
coefficient(5,matF)
param_frank <- coefficient(5,matF)[2][[1]]  # paramètre de la copule gaussienne
coefficient(6,matF)
param_joe <- coefficient(6,matF)[2][[1]]  # paramètre de la copule gaussienne
coefficient(1,matF)
param_gauss <- unname(coefficient(1,matF)[2][[1]])  # paramètre de la copule gaussienne
coefficient(2,matF) # possède le paramètre ainsi que le degré de liberté!
param_stud <- unname(coefficient(2,matF)[2][[1]])   # paramètres de la copule de Student
coefficient(3,matF)
param_gumb <- unname(coefficient(3,matF)[2][[1]])  # paramètre de la copule gaussienne
coefficient(4,matF)
param_clay <- unname(coefficient(4,matF)[2][[1]])  # paramètre de la copule gaussienne
coefficient(5,matF)
param_frank <- unname(coefficient(5,matF)[2][[1]])  # paramètre de la copule gaussienne
coefficient(6,matF)
param_joe <- unname(coefficient(6,matF)[2][[1]])  # paramètre de la copule gaussienne
normalCopula(sin((pi/2)*0.5))
normalCopula(sin((pi/2)*0.5)) * 2
t_max <- 240
Func12 = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),normalCopula(param_gauss)))
vrais_gauss = sum(sapply(1:t_max, function(t) Func12(x,t)))
Func12 = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),normalCopula(param_gauss, dim = 4)))
vrais_gauss = sum(sapply(1:t_max, function(t) Func12(x,t)))
Func_stud = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),tCopula(param_stud, dim = 4)))
vrais_stud = sum(sapply(1:t_max, function(t) Func_stud(x,t)))
Func_stud = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),tCopula(param_stud[1], dim = 4)))
vrais_stud = sum(sapply(1:t_max, function(t) Func_stud(x,t)))
Func_gumb = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),gumbelCopula(param_gumb, dim = 4)))
vrais_gumb = sum(sapply(1:t_max, function(t) Func_gumb(x,t)))
Func_clay = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),claytonCopula(param_clay, dim = 4)))
vrais_clay = sum(sapply(1:t_max, function(t) Func_clay(x,t)))
Func_frank = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),frankCopula(param_frank, dim = 4)))
vrais_frank = sum(sapply(1:t_max, function(t) Func_frank(x,t)))
Func_joe = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),joeCopula(param_joe, dim = 4)))
vrais_joe = sum(sapply(1:t_max, function(t) Func_joe(x,t)))
Func_stud = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),tCopula(param = param_stud[1], df = param_stud[2] , dim = 4)))
vrais_stud = sum(sapply(1:t_max, function(t) Func_stud(x,t)))
Func_gauss = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),normalCopula(param_gauss+0.02, dim = 4)))
vrais_gauss = sum(sapply(1:t_max, function(t) Func_gauss(x,t)))
Func_gauss = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),normalCopula(param_gauss-0.02, dim = 4)))
vrais_gauss = sum(sapply(1:t_max, function(t) Func_gauss(x,t)))
Func_gauss = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),normalCopula(param_gauss, dim = 4)))
vrais_gauss = sum(sapply(1:t_max, function(t) Func_gauss(x,t)))
Func1 = function(x,t) log(dCopula(c(matF[,1][t],matF[,3][t]),normalCopula(sin((pi/2) * x[1]), dim = 4)))
L1 = function(x, t_max) -sum(sapply(1:t_max, function(t) Func1(x,t)))
x <- r_1 #par default, b0 = ln(r(1)).
###matrice d'autocorrélation:
r_1 = acf(matF, lag = 1,plot=F)$acf[2,1,1]
if(r_1<0){
r_1 = 0.01
}
t_max = nrow(matF)
result = matrix(NA, nrow = 5, ncol = 1)
x <- r_1 #par default, b0 = ln(r(1)).
optimize(L1, c(3,100000), t_max = 240)
result[1,]  <- optim(x,L1,t_max = T, lower = -Inf, upper = Inf)$par
Func1 = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),normalCopula(sin((pi/2) * x[1]), dim = 4)))
L1 = function(x, t_max) -sum(sapply(1:t_max, function(t) Func1(x,t)))
x <- r_1 #par default, b0 = ln(r(1)).
optimize(L1, c(3,100000), t_max = 240)
result[1,]  <- optim(x,L1,t_max = T, lower = -Inf, upper = Inf)$par
optimize(L1, c(-Inf,Inf), t_max = 240)
Func_stud = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),tCopula(param = param_stud[1], df = param_stud[2]+1 , dim = 4)))
vrais_stud = sum(sapply(1:t_max, function(t) Func_stud(x,t)))
Func_stud = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),tCopula(param = param_stud[1], df = param_stud[2] , dim = 4)))
vrais_stud = sum(sapply(1:t_max, function(t) Func_stud(x,t)))
Func_stud = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3],matF[t,4]),tCopula(param = param_stud[1], df = param_stud[2]+0.01 , dim = 4)))
vrais_stud = sum(sapply(1:t_max, function(t) Func_stud(x,t)))
logvraisemblance_des_cop = c(vrais_gauss,vrais_stud,vrais_gumb,vrais_clay,vrais_frank,vrais_joe)
AIC_des_modeles = 2*nb_param - 2*(logvraisemblance_des_cop)
AIC_des_modeles = 2 - 2*(logvraisemblance_des_cop)
BIC_des_modeles = log(240) - 2 * logvraisemblance_des_cop
AIC_des_modeles
BIC_des_modeles
Beta_estim_reel
tableauAIC <- as.data.frame(AIC_des_modeles)
colnames(tableauAIC) <- c("Gauss", "Student", "Gumbel", "Clayton", "Frank", "Joe")
View(tableauAIC)
tableauAIC <- t(as.data.frame(AIC_des_modeles))
colnames(tableauAIC) <- c("Gauss", "Student", "Gumbel", "Clayton", "Frank", "Joe")
tableauAIC <- t(as.data.frame(AIC_des_modeles))
colnames(tableauAIC) <- c("Gauss", "Student", "Gumbel", "Clayton", "Frank", "Joe")
tableauAIC
tableauBIC <- t(as.data.frame(BIC_des_modeles))
colnames(tableauBIC) <- c("Gauss", "Student", "Gumbel", "Clayton", "Frank", "Joe")
tableauBIC
donnees <- read.table(file = 'C:/Users/bera1923/Desktop/CeCS - Consultations/Clients et Clientes/Zidane Toffa/donnees.txt', sep = "\t", header = TRUE)
Att <- donnees[,1]                   # Copie la première colonne
donnees <- donnees[,-1]              # Enlève la première colonne
donneesFinal <- cbind(donnees,Att)   # Colle la copie à la fin du tableau
colnames(donneesFinal) <- c("RecBro", "Rxt", "Slot", "Snir", "Tim", "TotBusy", "TotLost", "Att")
set.seed(12)
echaEntr <- donneesFinal$Att %>%
createDataPartition(p = 0.8, list = FALSE)    # 80% pour entraînement, 20% pour Test
donneesEntr  <- donneesFinal[echaEntr, ]  # données d'entraînement
donneesTest <- donneesFinal[-echaEntr, ]  # données test
# Pour le modèle lasso
x <- model.matrix(Att~., donneesEntr)[,-1]   # Sur R, on doit séparer les variables x et y pour Lasso
y <- donneesEntr$Att                         # On obtient x et y ainsi
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
# Fit le modèle final sur les données d'entraînement
model.lasso <- glmnet(x, y, alpha = 1, family = "binomial",
lambda = cv.lasso$lambda.min)
# Coefficients de la régression
coef(model.lasso)
# Prédictions
x.test <- model.matrix(Att ~., donneesTest)[,-1]
prob <- model.lasso %>% predict(newx = x.test)
ClassPred <- ifelse(prob > 0.5, 1, 0)
# Précision
ClassObs <- donneesTest$Att
mean(ClassPred == ClassObs)
# Stepwise model
step.model <- glm(Att ~., data = donneesEntr, family = binomial, control = glm.control(maxit = 50)) %>%
stepAIC(trace = TRUE)
# Coefficients de la régression
coef(step.model)
summary(step.model)
# Prédictions
prob <- predict(step.model, donneesTest, type = "response")
ClassPred <- ifelse(prob > 0.5, 1, 0)
# Précision
ClassObs <- donneesTest$Att
mean(ClassPred==donneesEntr$Att)
cor(donneesFinal, method = "pearson")
col1 <- donneesFinal[,1]  # RecBro
col2 <- donneesFinal[,2]  # Rxt
col3 <- donneesFinal[,6]  # TotBusy
col4 <- donneesFinal[,8]  # Att
ntabFinal <- cbind.data.frame(col1,col2,col3,col4)           # coller les 4 colonnes
colnames(ntabFinal) <- c("RecBro", "Rxt", "TotBusy", "Att")  # renommer les colonnes
ntabFinal
es_p <- mean(ntabFinal[,4])   # Effectue la moyenne des Att (Somme des 0 et 1 divisé en n = 240 attaques)
es_p   # la probabilité d'attaque est de 0.2083333
Fn_1 <- ecdf(ntabFinal[,1])  # Fonction de répartition empirique
Fn_2 <- ecdf(ntabFinal[,2])  # Fonction de répartition empirique
Fn_3 <- ecdf(ntabFinal[,3])  # Fonction de répartition empirique
plot(Fn_1, verticals = TRUE, do.points = FALSE, main = "Fonction de répartition de la variable RecBro")
plot(Fn_2, verticals = TRUE, do.points = FALSE, main = "Fonction de répartition de la variable Rxt")
plot(Fn_3, verticals = TRUE, do.points = FALSE, main = "Fonction de répartition de la variable TotBusy")
matF <- matrix(NA, nrow = nrow(ntabFinal), ncol = ncol(ntabFinal)-1)     # Création de la matrice des répartition
matF[,1] <- nrow(ntabFinal) / (nrow(ntabFinal)+1) * Fn_1(ntabFinal[,1])  # première colonne (Rescaled distribution)
matF[,2] <- nrow(ntabFinal) / (nrow(ntabFinal)+1) * Fn_2(ntabFinal[,2])  # deuxième colonne (Rescaled distribution)
matF[,3] <- nrow(ntabFinal) / (nrow(ntabFinal)+1) * Fn_3(ntabFinal[,3])  # troisième colonne (Rescaled distribution)
matF
MatntabFinal <- as.matrix(ntabFinal)
# Copules: 1 = Gaussienne, 2 = Student, 3 = Gumbel, 4 = Clayton, 5 = Frank, 6 = Joe,
coefficient <- function(copule, matrice){
if(copule == 1){
cop <- normalCopula(dim = 3)
t <- "La copule gaussienne possède un paramètre égal à"
} else if(copule == 2){
cop <- tCopula(dim = 3)
t <- "La copule Student possède un paramètre égal à"
} else if(copule == 3){
cop <- gumbelCopula(dim = 3)
t <- "La copule Gumbel possède un paramètre égal à"
} else if(copule == 4){
cop <- claytonCopula(dim = 3)
t <- "La copule Clayton possède un paramètre égal à"
} else if(copule == 5){
cop <- frankCopula(dim = 3)
t <- "La copule de Frank possède un paramètre égal à"
} else if(copule == 6){
cop <- joeCopula(dim = 3)
t <- "La copule de Joe possède un paramètre égal à"
}
fit <- fitCopula(cop, matrice, method = "mpl")
return(list((paste(t, coef(fit), sep = " ")),coef(fit)))
}
coefficient(1,matF)
param_gauss <- unname(coefficient(1,matF)[2][[1]])  # paramètre de la copule gaussienne
coefficient(2,matF)                                 # possède le paramètre ainsi que le degré de liberté!
param_stud <- unname(coefficient(2,matF)[2][[1]])   # paramètres de la copule de Student
coefficient(3,matF)
param_gumb <- unname(coefficient(3,matF)[2][[1]])  # paramètre de la copule Gumbel
coefficient(4,matF)
param_clay <- unname(coefficient(4,matF)[2][[1]])  # paramètre de la copule Clayton
coefficient(5,matF)
param_frank <- unname(coefficient(5,matF)[2][[1]])  # paramètre de la copule Frank
coefficient(6,matF)
param_joe <- unname(coefficient(6,matF)[2][[1]])  # paramètre de la copule Joe
t_max <- nrow(ntabFinal)
Func_gauss = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3]),normalCopula(param_gauss, dim = 3)))
vrais_gauss = sum(sapply(1:t_max, function(t) Func_gauss(x,t)))
Func_stud = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3]),tCopula(param = param_stud[1], df = param_stud[2] , dim = 3)))
vrais_stud = sum(sapply(1:t_max, function(t) Func_stud(x,t)))
Func_gumb = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3]),gumbelCopula(param_gumb, dim = 3)))
vrais_gumb = sum(sapply(1:t_max, function(t) Func_gumb(x,t)))
Func_clay = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3]),claytonCopula(param_clay, dim = 3)))
vrais_clay = sum(sapply(1:t_max, function(t) Func_clay(x,t)))
Func_frank = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3]),frankCopula(param_frank, dim = 3)))
vrais_frank = sum(sapply(1:t_max, function(t) Func_frank(x,t)))
Func_joe = function(x,t) log(dCopula(c(matF[t,1],matF[t,2],matF[t,3]),joeCopula(param_joe, dim = 3)))
vrais_joe = sum(sapply(1:t_max, function(t) Func_joe(x,t)))
logvraisemblance_des_cop = c(vrais_gauss,vrais_stud,vrais_gumb,vrais_clay,vrais_frank,vrais_joe)
AIC_des_modeles = 2 - 2*(logvraisemblance_des_cop)
BIC_des_modeles = log(nrow(ntabFinal)) - 2 * logvraisemblance_des_cop
tableauAIC <- t(as.data.frame(AIC_des_modeles))
colnames(tableauAIC) <- c("Gauss", "Student", "Gumbel", "Clayton", "Frank", "Joe")
tableauAIC
tableauBIC <- t(as.data.frame(BIC_des_modeles))
colnames(tableauBIC) <- c("Gauss", "Student", "Gumbel", "Clayton", "Frank", "Joe")
tableauBIC
estim_prob <- c()
which.min(tableauAIC)
which.min(tableauBIC)
is(which.min(tableauAIC) == which.min(tableauBIC))
isTRUE(which.min(tableauAIC) == which.min(tableauBIC))
if(isTRUE(which.min(tableauAIC) == which.min(tableauBIC))){
copgagn <- which.min(tableauAIC)
}
if(isTRUE(which.min(tableauAIC) == which.min(tableauBIC)))
copgagn <- which.min(tableauAIC)
if(isTRUE(which.min(tableauAIC) == which.min(tableauBIC))){
copgagn <- which.min(tableauAIC)
} else
"Nous avons un problème au AIC/BIC"
library(spcopula)
BiCop(family = 1, par = 0.1655, tau = NULL, check.pars = TRUE)
cCopula(matF, copula = normalCopula(param_gauss,dim = 3))
estim_prob <-
testing1 <- 1 - cCopula(matF, copula = normalCopula(param_gauss,dim = 3))
testing1
estim_prob <-
col4 <- c(rep(1 - es_p), n = 240)
estim_prob <-
col4 <- rep((1 - es_p), n = 240)
?rep
estim_prob <-
col4 <- rep((1 - es_p), times = 240)
matfinal <- cbind(matF,col4)
View(matF)
View(matfinal)
testing1 <- 1 - cCopula(matfinal, copula = normalCopula(param_gauss,dim = 3))
testing1
testing1 <- 1 - cCopula(matfinal, copula = normalCopula(param_gauss,dim = 4))
testing1
testing1 <- 1 - cCopula(matfinal, copula = tCopula(param_stud[1], df = param_stud[2], ,dim = 4))
testing1
install.packages("rvinecopulib")
library(rvinecopulib) # Estimation à l'aide de copules
pseudo_obs(ntabFinal)
matF
vinecop(matF, var_types = c("c","c","c"))
vinecop(matF, var_types = c("c","c","c"), par_method = "mle")
fit <- vinecop(matF, var_types = c("c","c","c"), par_method = "mle")
summary(fit)
plot(fit)
install.packages("ggraph")
library(ggraph) # Graphique des copules
plot(fit)
contour(fit)
vinecop(matF, var_types = c("c","c","c"), par_method = "mle")
summary(fit)
fit <- vinecop(matF, var_types = c("c","c","c"), par_method = "mle", family_set = "parametric")
summary(fit)
fit <- vinecop(matF, var_types = c("c","c","c"), par_method = "mle", family_set = "itau")
summary(fit)
plot(fit)
contour(fit)
fit <- vinecop(matF, var_types = c("c","c","c"), par_method = "mle", family_set = "parametric")
summary(fit)
plot(fit)
contour(fit)
RVineCopSelect(matF)
